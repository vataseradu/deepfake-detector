\documentclass[12pt, a4paper]{article}

% --- PACHETE ESENȚIALE ---
\usepackage[utf8]{inputenc}       % Suport diacritice
\usepackage[T1]{fontenc}          % Font encoding corect
\usepackage[romanian]{babel}      % Limba română
\usepackage{geometry}             % Margini
\usepackage{graphicx}             % Imagini
\usepackage{amsmath}              % Formule matematice
\usepackage{booktabs}             % Tabele profesionale
\usepackage{float}                % Poziționare imagini [H]
\usepackage{hyperref}             % Linkuri interactive
\usepackage{setspace}             % Spațiere text
\usepackage{titlesec}             % Formatare titluri
\usepackage{caption}              % Formatare descrieri figuri
\usepackage{xcolor}               % Pentru culori în link-uri

% --- CONFIGURĂRI STIL ---
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}
\setstretch{1.25}                 % Spațiere aerisită

% Formatare titluri: Sentence case (Doar prima literă mare)
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

% Configurare Metadata și Link-uri
\hypersetup{
    colorlinks=true,
    linkcolor=black,        % Link-uri interne negre (cuprins, figuri)
    filecolor=black,      
    urlcolor=blue,          % URL-uri albastre (pentru aplicație)
    citecolor=black,
    pdftitle={Sistem Hibrid Deepfake Detection},
    pdfauthor={Radu-Petruț Vătase}
}

\begin{document}

% --- PAGINA DE TITLU ---
\begin{center}
    \vspace{1cm}
    
    {\LARGE \textbf{Sistem hibrid pentru detectarea imaginilor deepfake utilizând analiză spectrală și rețele neuronale convoluționale}}
    
    \vspace{0.5cm}
    
    \textit{Student:} \\
    \textbf{Radu-Petruț Vătase}

     \vspace{0.5cm}
    \textit{Profesor coordonator:} \\
    \textbf{Conf. dr. Emil Simion}
     \vspace{0.5cm}

    \textit{Teoria Codării și Stocării Informației}
    
    {\small Ianuarie 2026}
\end{center}

% --- ABSTRACT ---
\begin{abstract}
    \noindent Prezenta lucrare propune un sistem hibrid pentru detectarea imaginilor generate sintetic (Deepfake), adresând provocările integrității informației digitale. Arhitectura soluției combină analiza matematică în domeniul frecvenței (prin \textit{Fast Fourier Transform} - FFT), algoritmi de Machine Learning clasic (\textit{Random Forest}) și tehnici avansate de Deep Learning (\textit{CNN Xception}). Studiul comparativ demonstrează limitările abordărilor bazate pe trăsături extrase manual (acuratețe 54\%) față de robustețea rețelelor neuronale convoluționale antrenate în cloud (acuratețe validată de 74.7\% în prima fază de antrenare, cu un scor AUC de 0.827). Suplimentar, sistemul integrează un modul de \textit{Explainable AI} bazat pe modelul GPT-4o pentru interpretarea semantică a anomaliilor spectrale, accesibil printr-o interfață web publică.
    
    \vspace{0.3cm}
    \noindent \textbf{Cuvinte cheie:} Deepfake, Rețele neuronale convoluționale, Analiză spectrală, Securitate cibernetică.
\end{abstract}

% --- CONȚINUT ---

\section{Introducere}
În era digitală actuală, integritatea informației vizuale este critică. Avansul rețelelor generative antagoniste (GANs) a făcut posibilă crearea de falsuri extrem de convingătoare. Această lucrare abordează problema detecției automate a acestor imagini prin metode complementare, oferind o soluție accesibilă cercetătorilor și jurnaliștilor.

\section{Fundamentare teoretică}
Detectarea falsurilor se bazează pe ipoteza că generarea sintetică introduce anomalii statistice invizibile ochiului uman, dar detectabile matematic.

\subsection{Analiza în domeniul frecvenței (FFT)}
Transformata Fourier 2D este utilizată pentru a identifica artefactele periodice introduse de operațiile de \textit{upsampling} din GAN-uri. Formula utilizată pentru spectrul de frecvență este:

\begin{equation}
F(u,v) = \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} I(x,y) \cdot e^{-j2\pi(\frac{ux}{M} + \frac{vy}{N})}
\end{equation}

Imaginile deepfake prezintă adesea anomalii în benzile de înaltă frecvență, vizibile în profilul radial al spectrului.

\textbf{Limitări:} Inițial, abordarea proiectului s-a concentrat pe analiza FFT ca metodă principală de detecție. Însă, \textbf{generatoarele moderne de imagini (StyleGAN3, DALL-E 3, Midjourney v6) au evoluat semnificativ}, producând imagini sintetice cu distribuții spectrale aproape identice cu cele ale imaginilor reale. Diferențele în spectrogramele FFT au devenit imperceptibile, făcând imposibilă antrenarea unui model de Machine Learning sau a unui API AI (GPT-4o) să distingă între graficele spectrale ale imaginilor reale versus generate. Această limitare a impus trecerea către metode de Deep Learning care operează direct pe pixeli.



\subsection{Arhitectura CNN Xception}
Pentru componenta de Deep Learning, s-a utilizat modelul Xception pre-antrenat pe ImageNet. Această arhitectură folosește \textit{Depthwise Separable Convolutions}, fiind eficientă computațional și performantă în extragerea trăsăturilor spațiale complexe \cite{xception}.



\section{Metodologie și arhitectură}
Sistemul este compus din trei module interconectate, fiecare contribuind cu o perspectivă complementară:

\begin{enumerate}
    \item \textbf{Modul FFT (Analiză Spectrală):} Transformată Fourier 2D pentru detectarea anomaliilor în domeniul frecvenței. Oferă explicabilitate vizuală prin spectrograme.
    \item \textbf{Modul Random Forest:} Clasificator bazat pe 5 caracteristici extrase manual (energie high-freq, centroid spectral, flatness, edge density, color entropy). Servește ca baseline pentru comparație.
    \item \textbf{Modul CNN Xception:} Rețea neuronală convolut,ională deep, pre-antrenată pe ImageNet și adaptată prin Transfer Learning pe 100.000 imagini deepfake/reale.
\end{enumerate}

În implementarea finală, \textbf{CNN Xception reprezintă componenta decisivă} datorită performanței superioare demonstrate (74.67\% accuracy, AUC 0.8273). Modulele FFT și Random Forest sunt păstrate ca \textbf{analiză comparativă}, oferind perspective complementare pentru înțelegerea deciziilor și validarea educațională a diferitelor abordări de detecție.

\subsection{Seturi de date}
Au fost utilizate două seturi de date distincte:
\begin{itemize}
    \item \textbf{Dataset Random Forest:} 2,041 imagini (echilibrat), folosit pentru baseline.
    \item \textbf{Dataset CNN:} 100.000 imagini din setul "140k Real and Fake Faces" \cite{dataset}, selectate pentru a asigura diversitatea trăsăturilor.
\end{itemize}

\subsection{Antrenarea modelului în Google Colab}
Dată fiind dimensiunea setului de date (100.000 imagini) și complexitatea modelului Xception, resursele locale (placă video RTX 3050) s-au dovedit insuficiente din cauza incompatibilităților driverelor CUDA cu librăria TensorFlow.

S-a optat pentru mediul Google Colab, utilizând acceleratorul grafic Tesla T4 (16GB VRAM). Procesul de antrenare a fost structurat în două faze (Transfer Learning):
\begin{enumerate}
    \item \textbf{Faza 1 (Straturi Blocate):} Menținerea constantă a parametrilor straturilor pre-antrenate Xception și antrenarea exclusivă a stratului de clasificare finală. Parametrii utilizați:
    \begin{itemize}
        \item Learning Rate: 0.001
        \item Loss Function: Binary Crossentropy
        \item Optimizator: Adam
    \end{itemize}
    \item \textbf{Faza 2 (Ajustare Fină):} Activarea antrenării pentru ultimele 20 de straturi (10 epoci), permițând modelului să învețe artefacte specifice deepfake-urilor.
\end{enumerate}

\section{Implementare și interfață grafică}

\subsection{Aplicația web Streamlit}
Sistemul a fost implementat sub forma unei aplicații web interactive, disponibilă public la adresa:

\begin{center}
    \href{https://deepfake-detector-tcsivtstcsitcsi.streamlit.app/}{\textbf{https://deepfake-detector-tcsivtstcsitcsi.streamlit.app/}}
\end{center}

Interfața este construită pe principiul transparenței (Explainable AI). Utilizatorul nu primește doar un verdict binar (Real/Fake), ci o analiză detaliată compusă din:

\begin{itemize}
    \item \textbf{Analiza spectrală vizuală:} Afișarea spectrului FFT 2D și a profilului radial.
    \item \textbf{Interpretare AI:} Integrarea API-ului OpenAI (GPT-4o) care "traduce" graficele tehnice în limbaj natural.
    \item \textbf{Predicție CNN:} Componenta decisivă care furnizează verdictul final bazat pe arhitectura Xception antrenată. Modulele FFT și Random Forest sunt afișate ca referință comparativă pentru validarea deciziei.
\end{itemize}

\section{Rezultate experimentale}

\subsection{Comparație performanță}
Tabelul 1 prezintă rezultatele comparative, incluzând datele obținute în urma antrenării modelului CNN în Faza 1 pe GPU Tesla T4 în Google Colab.

\begin{table}[H]
    \centering
    \caption{Comparație între metodele utilizate}
    \vspace{0.2cm}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Metodă} & \textbf{Accuracy} & \textbf{AUC} & \textbf{Recall} & \textbf{Observații} \\
        \midrule
        Random Forest & 54.0\% & - & 20\% (Fake) & Bias sever spre Real \\
        \textbf{CNN Ep. 3 (Best)} & \textbf{74.67\%} & \textbf{0.8273} & \textbf{78.9\%} & \textbf{Peak val, LR=0.001} \\
        CNN Estimat (Ep. 20) & $\sim$88-92\% & $\sim$0.92 & $>$85\% & După fine-tuning Faza 2 \\
        \bottomrule
    \end{tabular}
    \label{tab:rezultate}
\end{table}

\subsection{Analiza convergenței}
Antrenamentul modelului Xception pe GPU T4 (Google Colab) a demonstrat o capacitate superioară de generalizare. Tabelul 2 prezintă evoluția metrică în primele 5 epoci complete:

\begin{table}[H]
    \centering
    \caption{Puncte de verificare antrenare CNN - Faza 1 (Straturi Blocate, LR=0.001)}
    \vspace{0.2cm}
    \small
    \begin{tabular}{cccccc}
        \toprule
        \textbf{Epoca} & \textbf{Train Acc} & \textbf{Val Acc} & \textbf{Val AUC} & \textbf{Val Recall} & \textbf{Status} \\
        \midrule
        1 & 66.65\% & 73.52\% & 0.8150 & 78.04\% & Salvat \\
        2 & 70.46\% & 74.43\% & 0.8231 & 79.46\% & Salvat \\
        \textbf{3} & \textbf{70.45\%} & \textbf{74.67\%} & \textbf{0.8273} & \textbf{78.90\%} & \textbf{Optim} \\
        4 & 70.09\% & 73.23\% & 0.8248 & 83.37\% & Nesalvat \\
        5 & 70.06\% & 74.40\% & 0.8279 & 80.73\% & LR redus \\
        \bottomrule
    \end{tabular}
    \label{tab:checkpoints}
\end{table}

\textbf{Observații cheie:}
\begin{itemize}
    \item \textbf{Peak în Epoca 3:} Val Accuracy 74.67\%, AUC 0.8273, Loss 0.5207
    \item \textbf{No overfitting:} Val Accuracy > Train Accuracy în toate epocile
    \item \textbf{Epoca 5:} Reducerea automată a learning rate de la 0.001 la 0.0005 (ReduceLROnPlateau callback)
    \item \textbf{Timp/epocă:} ~34-37 minute pe Tesla T4 (2068-2212s)
\end{itemize}

% SCREENSHOT GOOGLE COLAB
\begin{figure}[H]
    \centering
    % \includegraphics[width=0.9\textwidth]{colab_faza1_training.png}
    
    \caption{Screenshot antrenare Faza 1 în Google Colab - Evoluția metrică pe 5 epoci (GPU Tesla T4).}
    \label{fig:colab_training}
\end{figure}

\section{Concluzii}
Sistemul hibrid propus validează ipoteza că deep learning-ul este superior metodelor clasice pentru această sarcină, în special când este antrenat pe seturi mari de date folosind infrastructură cloud (Google Colab). Rezultatele preliminare de 74.7\% acuratețe și 0.827 AUC confirmă eficiența arhitecturii Xception. Totuși, analiza spectrală rămâne valoroasă pentru explicabilitate. Integrarea LLM-urilor în interfața Streamlit oferă un strat semantic necesar pentru utilizatorii finali, transformând un "Black Box" într-un instrument transparent de auditare media.

% --- BIBLIOGRAFIE ---
\begin{thebibliography}{9}

\bibitem{xception}
Chollet, F., "Xception: Deep Learning with Depthwise Separable Convolutions", \textit{CVPR}, 2017.

\bibitem{durall}
Durall, R., et al., "Watch your Up-Convolution: CNN Based Generative Colorization Exposes Fake Images", 2020.

\bibitem{stylegan}
Karras, T., et al., "Analyzing and Improving the Image Quality of StyleGAN", \textit{CVPR}, 2020.

\bibitem{dataset}
Kaggle, "140k Real and Fake Faces Dataset", 2023.

\bibitem{gemini}
OpenAI, "GPT-4 Technical Report", 2024.

\end{thebibliography}

\end{document}